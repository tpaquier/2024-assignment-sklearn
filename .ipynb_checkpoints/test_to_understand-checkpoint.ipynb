{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459c2632-9b7d-4cf8-af2c-84d5ea4694fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5941809f-3914-4f5e-b1e7-9e6dee858991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Assignment - making a sklearn estimator and cv splitter.\n",
    "\n",
    "The goal of this assignment is to implement by yourself:\n",
    "\n",
    "- a scikit-learn estimator for the KNearestNeighbors for classification\n",
    "  tasks and check that it is working properly.\n",
    "- a scikit-learn CV splitter where the splits are based on a Pandas\n",
    "  DateTimeIndex.\n",
    "\n",
    "Detailed instructions for question 1:\n",
    "The nearest neighbor classifier predicts for a point X_i the target y_k of\n",
    "the training sample X_k which is the closest to X_i. We measure proximity with\n",
    "the Euclidean distance. The model will be evaluated with the accuracy (average\n",
    "number of samples corectly classified). You need to implement the `fit`,\n",
    "`predict` and `score` methods for this class. The code you write should pass\n",
    "the test we implemented. You can run the tests by calling at the root of the\n",
    "repo `pytest test_sklearn_questions.py`. Note that to be fully valid, a\n",
    "scikit-learn estimator needs to check that the input given to `fit` and\n",
    "`predict` are correct using the `check_*` functions imported in the file.\n",
    "You can find more information on how they should be used in the following doc:\n",
    "https://scikit-learn.org/stable/developers/develop.html#rolling-your-own-estimator.\n",
    "Make sure to use them to pass `test_nearest_neighbor_check_estimator`.\n",
    "\n",
    "\n",
    "Detailed instructions for question 2:\n",
    "The data to split should contain the index or one column in\n",
    "datatime format. Then the aim is to split the data between train and test\n",
    "sets when for each pair of successive months, we learn on the first and\n",
    "predict of the following. For example if you have data distributed from\n",
    "november 2020 to march 2021, you have have 4 splits. The first split\n",
    "will allow to learn on november data and predict on december data, the\n",
    "second split to learn december and predict on january etc.\n",
    "\n",
    "We also ask you to respect the pep8 convention: https://pep8.org. This will be\n",
    "enforced with `flake8`. You can check that there is no flake8 errors by\n",
    "calling `flake8` at the root of the repo.\n",
    "\n",
    "Finally, you need to write docstrings for the methods you code and for the\n",
    "class. The docstring will be checked using `pydocstyle` that you can also\n",
    "call at the root of the repo.\n",
    "\n",
    "Hints\n",
    "-----\n",
    "- You can use the function:\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "to compute distances between 2 sets of samples.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.utils.validation import check_array\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "\n",
    "class KNearestNeighbors(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"KNearestNeighbors classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=1):  # noqa: D107\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fitting function.\n",
    "\n",
    "         Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            Data to train the model.\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            Labels associated with the training data.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        self : instance of KNearestNeighbors\n",
    "            The current instance of the classifier\n",
    "        \"\"\"\n",
    "        #check that the arrays are ok\n",
    "        X_checked = check_array(X) \n",
    "        y_checked = check_array(y)\n",
    "        X_conv, y_conv = check_X_y(X, y)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_test_samples, n_features)\n",
    "            Data to predict on.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        y : ndarray, shape (n_test_samples,)\n",
    "            Predicted class labels for each test data sample.\n",
    "        \"\"\"\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Calculate the score of the prediction.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            Data to score on.\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            target values.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        score : float\n",
    "            Accuracy of the model computed for the (X, y) pairs.\n",
    "        \"\"\"\n",
    "        return 0.\n",
    "\n",
    "\n",
    "class MonthlySplit(BaseCrossValidator):\n",
    "    \"\"\"CrossValidator based on monthly split.\n",
    "\n",
    "    Split data based on the given `time_col` (or default to index). Each split\n",
    "    corresponds to one month of data for the training and the next month of\n",
    "    data for the test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_col : str, defaults to 'index'\n",
    "        Column of the input DataFrame that will be used to split the data. This\n",
    "        column should be of type datetime. If split is called with a DataFrame\n",
    "        for which this column is not a datetime, it will raise a ValueError.\n",
    "        To use the index as column just set `time_col` to `'index'`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, time_col='index'):  # noqa: D107\n",
    "        self.time_col = time_col\n",
    "\n",
    "    def get_n_splits(self, X, y=None, groups=None):\n",
    "        \"\"\"Return the number of splitting iterations in the cross-validator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where `n_samples` is the number of samples\n",
    "            and `n_features` is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        n_splits : int\n",
    "            The number of splits.\n",
    "        \"\"\"\n",
    "        return 0\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where `n_samples` is the number of samples\n",
    "            and `n_features` is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        idx_train : ndarray\n",
    "            The training set indices for that split.\n",
    "        idx_test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        n_splits = self.get_n_splits(X, y, groups)\n",
    "        for i in range(n_splits):\n",
    "            idx_train = range(n_samples)\n",
    "            idx_test = range(n_samples)\n",
    "            yield (\n",
    "                idx_train, idx_test\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8bc38f8-ad40-4d11-990c-d4f885e04bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = np.ones((2,2))\n",
    "test_2 = np.ones((2,2))*4\n",
    "\n",
    "test_2[:,0] *= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e806338-ce70-402a-a617-fe12dc7c9140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "384ee8e0-e95d-4eee-99ea-446d036a5bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.,  4.],\n",
       "       [12.,  4.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0e2c719-dc82-4ac5-89b0-d62d70e52de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.40175425, 11.40175425],\n",
       "       [11.40175425, 11.40175425]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances(test_1,test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9d36979-3142-4adb-835a-4d42fac1e02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebb63ff-9fa9-4372-a75b-19568e29200f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
